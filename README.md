# epilogos-web

This is a React application for presenting epilogos and associated simsearch data using a HiGlass visualization component, which pulls data from "tilesets" hosted on a separate HiGlass server (at this time, https://explore.altius.org, or locally, if using the `higlass-manage` package). For local development, targets are provided for running a local HiGlass server instance with core files ingested to it, as well as a simsearch query service to retrieve simsearch results.

## Dataset overview

Scores datasets are generated by running the [epilogos](https://github.com/meuleman/epilogos) toolkit on chromatin state data. Scores and chromatic state files are subsequently turned into HiGlass-ready multivec tracks with the [clodius](https://github.com/higlass/clodius) toolkit. These multivec files are hosted on our private HiGlass server instance, and this web application requests data from that server to then visualize.

We have already performed the track generation and hosting step for so-called ["core" datasets](#core-assets) associated with some publications. But this can also be done for the user's own chromatin state data. Those results can be ingested into the user's own private HiGlass server, or instead be hosted on [resgen.io](https://resgen.io/) which is managed by the lead developer of HiGlass. The end user can use the ["custom asset"](#custom-assets) functionality, setting their local `epilogos-web` instance to point to files hosted on these services.

## Development

To run a local, portable `epilogos-web` frontend, please use the [Docker](#docker), [Initialization](#initialization) and [Core assets](#core-assets) instructions to do the initial setup. For ongoing development, use the [Ongoing](#ongoing) instructions.

### HiGlass service and core ingestion

#### Docker

For local development, we use [Docker Desktop](https://www.docker.com/products/docker-desktop/) run Docker containers that support a local HiGlass server and simsearch service. (For production, we use outside servers, as [discussed above](#dataset-overview). This document will not cover setup of production services.)

If you do not already have Docker Desktop installed, please first download and install it via their [instructions](https://docs.docker.com/desktop/). Or use package managers such as Homebrew, `yum`, or `apt` to install Docker. Please open this application and have it running in the background while following the next steps.

#### Initialization

Once Docker Desktop is installed and running, please run the following commands in order to set up a initial container and download/ingest core asset files:

```
npm run higlass-manage-install
npm run higlass-manage-start
npm run higlass-manage-prep-assets
npm run higlass-manage-ingest-core
```

Note: If you only have locally-generated epilogos and simsearch assets, and you do not want or need to download core assets, please skip the `higlass-manage-ingest-core` target and jump to the [Custom Assets](#custom-assets) section below.

The test core datasets can take between 10-20 minutes to download. Downloading the entirety of the core dataset collection will take considerably longer and require accordingly more disk space.

The `higlass-manage-ingest-core` scripts will calculate needed disk space and ask you to confirm this capacity is available before any files are retrieved.

Once the server is installed and datasets are ingested, install packages for the `epilogos-web` frontend application:

```
npm install
```

Use the `start` directive to open the development website:

```
npm run start
```

This launches the frontend at [http://localhost:3000](http://localhost:3000), with any overrides for settings related to ingested core assets, as well as data specified in the `local` property of the manifest.

#### Core assets

The core assets include files for epilogos and chromatin state matrix tracks rendered in the browser, for sets such as Roadmap, Boix et al., Gorkin et al., and IHEC. Additionally, simsearch data are part of this set and used for providing simsearch pattern results.

The `scripts/higlass_manage_ingest_core.py` Python script contains an `allowed_datasets` object that can be used to pull a local copy of a subset of the core epilogos asset set.

Or the entirety of sets can be pulled: For testing purposes, the `allowed_datasets` object is currently defined with a small subset of Roadmap tracks and simsearch data. To pull in the entirety of core datasets (if you have sufficient disk space), comment out `allowed_datasets` in this script and rerun the `npm run higlass-manage-ingest-core` target.

The `scripts/higlass_manage_ingest_core.py` script will calculate the disk space required and ask you to confirm downloading and ingesting assets, or the script will quit if insufficient disk space is available.

#### Custom assets

Custom datasets are epilogos and chromatin state matrix (multivec-formatted) tracks, and simsearch (tabix-formatted) files which you have generated with the [epilogos](https://github.com/meuleman/epilogos) toolkit and the [clodius](https://github.com/higlass/clodius) toolkit from your own chromatin state data, and hosted on your own HiGlass server or on [resgen.io](https://resgen.io).

You can use `epilogos-web` as a frontend viewer for exploring your custom-generated data. 

You will need to modify the `manifest.json` file with properties that specify where these data are hosted, so that the usual scripts can pull these in and put them in the right place for local services.

An example of how one might specify local data is provided in the file `manifest.coreAndLocal.json`, which shows how the `local` property is populated. This example includes a subset of Roadmap consortium data, but this can be used with any custom data you would like to import, so long as it uses the assembly `hg19`, `hg38`, or `mm10`.

You can copy the `manifest.coreAndLocal.json` file over to `manifest.json`, and then use `npm run higlass-manage-ingest-local` to download and ingest these custom data files into the HiGlass server and simsearch services.

Your data files must initially be hosted on a publicly-accessible web server and that server hostname should be specified in `hgMediaServer` and `simsearchMediaServer` properties within the local sample set (e.g., `vLocal` or whatever set name you like).

If you would also like to download and ingest core datasets alongside your custom local datasets, you can also then use `npm run higlass-manage-ingest-core`. You will need sufficient time and disk space to store custom and any core datasets.

##### Custom asset pathname rules

Epilogos filenames should follow this pattern, so that our scripts can find and import files:

```
${sampleSet}.${assembly}.${stateModel}.${groupName}.${saliency}.mv5
```

An example is: `vLocal.hg19.15.All_127_Roadmap_epigenomes.S1.mv5`

Chromatin state multivec filenames should follow this pattern:

```
${sampleSet}.${assembly}.${stateModel}.${groupName}.mv5
```

An example is: `vLocal.hg19.15.All_127_Roadmap_epigenomes.mv5`

Finally, simsearch assets should follow this pattern:

```
${hostname}/${sampleSet}/${assembly}/${stateModel}/${groupName}/${saliency}/${windowSize}/${windowSpan}/...
```

Examples would be: `https://explore.altius.org/tabix/recommender/v2/vLocal/hg19/15/All_127_Roadmap_epigenomes/S1/1/5/recommendations.bed.gz` and its associated index file: `https://explore.altius.org/tabix/recommender/v2/vLocal/hg19/15/All_127_Roadmap_epigenomes/S1/1/5/recommendations.bed.gz.tbi`

#### Ongoing

To run the local HiGlass and simsearch services on an ongoing basis, after initialization, simply start Docker Desktop and restart the `higlass-manage` service:

```
npm run higlass-manage-start
```

You will need to do this if you log out of your account or reboot your host computer.

Once this is done, run the development website:

```
npm run start
```

#### Stop

To stop the HiGlass and simsearch services, run:

```
npm run higlass-manage-stop
```

This does not remove any HiGlass and simsearch assets. This only stops the HiGlass server and simsearch instance from running on the specified ports. If you reboot your computer, you will need to restart the HiGlass server and simsearch instance via Docker Desktop (recommended) or `npm run higlass-manage-start`.

#### Cleanup

To stop the service and completely remove any downloaded/ingested tracks, simsearch assets, and the Python virtual environment used to manage the service, run:

```
npm run higlass-manage-clean
```

Note that if this target is run, all media and environment files are removed from local storage and it will be necessary to reinitialize via the [Initialization](#initialization) section.

#### Customizing the environment

Environment variables are stored in the project `.env` file that are used for configuring a local Python environment, a HiGlass server, and where that service stores its files. For example:

```
REACT_APP_HG_MANAGE_VIRTUAL_ENVIRONMENT=epilogos-hgManage
REACT_APP_HG_MANAGE_VIRTUAL_ENVIRONMENT_PYTHON_VERSION=python3.9
REACT_APP_HG_MANAGE_PORT=8989
REACT_APP_HG_MANAGE_NAME=epilogos
REACT_APP_HG_MANAGE_DATA_DIR=${HOME}/epilogos-hgManage-data
REACT_APP_HG_MANAGE_MEDIA_DIR=${HOME}/epilogos-hgManage-data/media
REACT_APP_HG_MANAGE_TEMP_DIR=${HOME}/epilogos-hgManage-data/tmp
```

Other variables are related to simsearch service management. Leaving these set to their default values is advised. You can change these if you have, for example, another service running on port `8989` or `9002`. Or if you would like core HiGlass assets stored elsewhere on your filesystem, such as an external storage volume that might have more free disk space, etc.

#### Customizing tracks

Custom epilgos tracks and track groups can be added to the `local` property of the project root `manifest.json` file. 

Track metadata should follow the schema defined in `manifest.schema.json`, which adheres to [JSON Schema Draft 2020-12](https://json-schema.org/draft/2020-12).

Tools such as [jsonschemavalidator.net](jsonschemavalidator.net) can be used to test and validate changes to the manifest.

Description keys in the schema help describe how properties are used to locate tracks in the HiGlass service and present tracks for display in the browser. Existing tracks in the `core` property can be used as working examples that show how metadata are defined and used.

Once the manifest is edited and validated, ingest custom datasets into the HiGlass service via:

```
npm run higlass-manage-ingest-local
```

Sufficient disk space will be required for storing tracks in the HiGlass service project folder defined in `REACT_APP_HG_MANAGE_MEDIA_DIR`.

Running the `higlass-manage-clean` target will remove local and core ingested tracks.